
tcsglobal.udemy.com
jioaman390
volume
ENI Will get deleted manually created will stay
AMI - image from the VM so that if we create same type of VM we can make use of AMI
Snapshot - we can take snapshot of storage sttached to VM
if volume is created in not encrypted than if you will try to create snapshot from volume it will also be not encrypted
we can give permission to EC2 or buckets from IAM that is from roles.
Network ACL - it is the where we can set restriction on inbound and outbound traffic on subnet. it attached to subnet. and attached to VPC.
security group - it attached to network interface and we can define the inbound and outbound traffic.it attached to NI . Ni get attached to VM
AMIs - Under images in EC2 is the image which we created from instance normally we create if we are installing multiple things in our server and we want 
another server with same set of software than we can create a image which will get stored under images under AMIs and we can use it while launching 
new VMs in AWS.
EBS and S3 - Both S3 and EBS gives the availability of 99.99%, but the only difference that occurs is that S3 is accessed via the internet using API's and EBS is accessed by the single instance attached to EBS
Amazon EFS and EBS 
Route 53
*************
its name is route 53 because dns service used to run on 53 port
A record - map hostname to IPV4
AAA - maps hostname to IPV6
CNAME - maps hostname to another hostname
NS - Name servers for hosted zone

CNAME vs Alias - hmm route 53 mai directly dns ko service se bind kr skte h jaise ALB,CloudFront or bhi services h uske liye hmme Alias ka use krna
padta h or isme 1k or fayda ye hota h ki hmm base dns ko bhi bind lr skte h jbki hmm CNAME mai base dns ko bind nhi kr skte kisi dusre dns k saath
Alias mai health check wgera bhi aa jata h.

Routing Policy
*****************
Simple Routing - yha par hmm 1 ya multiple ip mention kr skte h jha dns route krega but yha dns kisi bhi IP mai route kr skta h randomly
Weighted Routing - Yha par (total weight of all record/total weight of all record aise calculate krte h weight ko)(agar hmm record 0 kr denge to whaa 
traffic nhi jaiga or agar hmm sbka weight 0 kr denge to all record ko equal jaiga).to gska jyada weight hoga usko utna jyada baar route krega dns.
Latency based routing - isse hmm tb use krte h jb hmme latency kam krne hoti lets suppose hmare application multiple region mai run ho rha h to 
ab hmm ky krenge ki dns create krenge policy use krenge latency or different region k liye IP daal denge. taki jb gis region se request aye to wo
uss region wali IP pe redirect krde.
Failover routing policy - jb hmm failover routing policy select krte h to health chek define krte h record mai taki wo health check dekhe or agar wo unhealthy
ho to wo directly dusre wale route krde traffic dns se.
Geolocation routing policy - isme hmm ky krte h ki define krte h konse geography wale ko konse IP pe jana h. iska use case h jaise ki hmm india mai 
jo version apni application ka run kr rhe wo hindi maih to hmm ky krenge asia wali region ko uss ip pe dalenge jha hindi version ka application run
kiya h or baki sb english.
IP Based routing - isme ky hota h ki hmm define krte h ki agar iss CIDR block(set of IP address) wale se request aaiga to wo is IP mai jaiga or agar dusre CIBR block
se aaiga to wo dusre IP mai jaiga.
Multi Value routing - isme hmm ky krte h ki multiple target ip rakhte h or saath mai healthcheck attach krte h to jb bhi hmm dns ko hit krte h ye 
sirf healthy wale pe route krta h or agar koi unhealthy ho to usse remove kr deta h target se.

Hmm domain kisi bhi jagh se khareed skte h jaise ki hmne godaddy se khareed liye uske baad hmm usse register kr skte h AWS route53 mai hmm Hosted zone
create krenge or phir jo bhi name server hmme milte h route53 mai wo wale name server hmm go daddy mai edit krke update kr denge take hmm saare update
dns mai route53 se kr ske.
Health check in route53
****************************
hmm route53 mai health check create kr skte h or status or logs wgera bhi dekh skte has
hmm route53 mai health checks k bhi health check bna skte h jiase ki pehle mene define kiye health check 4 vm k liye uske baad mene wo health check
mai condition laga di ki koi 3 healthy honge to considered hoga healthy so final status healthy hoga.
Route 53 weighted record 
******************************
it means we can assign dns to multiple IPs and set the weight for it so that traffic can go based on the weight low will be 0 means no traffic will go
255 is maximum. 

TTL
***********
It means for how much time it will cash the dns resolve IP lets say we keep 24 hour so once we hit the dns from one server the resolve IP will get saved into cash 
and it will resolve the dns with same ip even if we change the value in route 53 for next 24 hours. if we choose less means 5 mints than in every
5 min route 53 will get the request and route 53 will get loaded so we need to set based on our requirement.

Latency
****************
we can use latency to route a traffic from route 53 we can create a dns and set a latency for different region let say if someone hitting dns from one zone 
it will get routed to that zone IP and it will always do the same if it is hitting from another zone it will get routed to another IP.

Beanstalk - internally it use cloud formation to create resources it use EC2 autoscale and other resources of AWS.

S3
*************
creating presigned url like we want to give access to someone for particular amount of time that time we can create a presigned url. got inside s3 bucket ->
click on object -> object actions -> share with a presigned url

Cloud Front (CDN)
***************
it is a global service
this can be used for the kind of cache like we will have cloud front on multiple location lets say someone in US is accessing data from S3 which is in different
country and we have setup cloudfront for us than cloudfront will take the data first time and from next time it will automatically give the data
from cache.
We can restrict the regions also like if we want to use cloud front for particular region like US and India so we can select US and India in CloudFront->
Distribution -> cloudFrontname -> Geographic restriction
Here also we will have concept of TTL after that timeperiod data will get refreshed into the cache of cloudfront.
cloud front ka use case ky h jaise hmm ec2 mai koi service run kr rhe h or phir hmm load balancer use kr rhe h access krne k liye ab koi log h jo service
ko access krna cah rhe h jo dusre region mai h to hmm cloudfront create krenge gsse help se hmm route krnge load balancer ko. abhi ky hoga edge location 
se wo data access kr skenge wo whaa cache ho jaiga or wo jaldi access kr painge. yaad rakhna cloud front gsko access krega wo public available hona
cheye kuki cloud front edge location se dusre edge location ko access krega.
isme hmm security k liye web application firewall(WAF) use kr skte h or hmm geographic location bhi select kr skte h, error page jo hmm error k time
aaiga , invalidation mai hmm uri de skte h ki un url ko main server se hee access krro

AWS Global Accelerator
************************
yha ky hota h ki agar mere application india mai deploy ho rakhe h or usse bhut saare log use kr rhe h outside india to unko slowness aa skte h usko fix
krne k liye hmm Global Accelerator use kr skte h usme ky hoga ki whaa k log edge location se requiest private AWS k through aaiga publicly nhi jaiga
gsse slowness nhi hoga.
ab difference ye h AWS Global Accelerator or Cloud Front mai ki cloud front mostly cache se serve krta h whee global accelerator hmesa site ko hit 
krke data deta h koi cache ka use nhi krta so global accelerator real time use application k liye h.

AWS Snow Family
********************
this the device which aws send you and you will be copying data into it and sending back to AWS

Storage Gateway
******************
isse hmm generally use krte h jb hmm hybrid cloud use krte h jaise ki agar mujhe onprem data or cloud data ko connect krna h to bridge ki tarh mai
storage gateway ko use krunga. ye gateway install hota h onprem server pe.
use cases 
- backup and restore

SQS Queue
SQS use cases are multiple jaise ki agar hmm koi cheez database mai dal rhe h or hmm kuch bhi miss nhi krne cahte to hmm SQS k through kr skte h
kuki agar 1k cheez koi SQS mai gye to wo delete krne pe hee hatti h ye read ho jaye tn hee hatti h aise mai jb tk data database mei nhi gya or
hmne htaya nhi tbtk wo SQS se nhi hatega.

agar hmme latency decrease krne h to pooling time badhana padega

dusra use case h ki hmm front end or backend k beech mai laga sakte h taki koi bhi request miss na ho jo front end se aa rhe ho.

SNS
***********
SNS AWS ki service jha se wo multiple jagh single message ko bhej skata h. jaise ki mujhe requirement is multiple jagh same request bhejne ki to mai 
SNS create krunga or usme wo HTTP,SQS, MailID add kr dunga or publish krunga to ye automatically message chla jaiga.

Kinesis
**********
Kinesis Data streaming - ye data streaming k liye use hota h 
Kinesis Data firehouse - ye data ko store krwane k kam ata h jaise ki hmm isko kinesis data streaming k saath bhi use kr skte h streaming k through
stream kiya whaa se kinesis data firehouse ki help se store krwa diya s3 mai ya Amazon openshift mai. or agar kuch failed hota h copy hone mai to hmm
condition daal k usse s3 mai bhi daal skte h.

IP address
************
https://www.ipaddressguide.com/
this you can use to check the IP address range in CIDR 

VPC
***************
hmm VPC create krenge , subnet create krenge 2 public naam se 2 private naam se , phir hmm internet gateway create krenge usko VPC jo hmne create
kiya h usme attach krenge uske baad hmm route table create krenge private or public . punlic wale mai hmm public wale subnet naam wale attach krenge or 
private wale mai private wale. phir hmm route table edit krenge public wale whaa hmm allow krenge 0.0.0.0/0 so that internet se traffic aa ske. 
uske baad hmm vm create krenge public subnet mai or jb vm create ho jaiga to uske pass internet ka access rhega. uske baad hmm vm create krenge 
private subnet mai uske security group mai allow krenge security group public vm wale ka. or phir hmm connect krenge private wale mai public wale se.

Ab agar hmme private subnet mai jo vm create kiya h usme internet access dena h to hmme NAT gateway create krna padega public subnet mai or connect krna 
padega vm se jo private subnet mai h.

NACL are stateless and will be attached on subnet level.
Security group stateful hota example h ki agar vm mai koi traffic ata h kuch service ko hit krta h to response usko mil jaiga kuki wo jha se aya whaa se 
chla jaiga even hmara outbound role mai deny bhi h to. par NACL k case mai aise nhi hota NACL stateless h wo traffic wapis jate hue bhi check krega outbound
rule or agar rule nhi hua to traffic block ho jaiga. ab agar security group mai outbound rule nhi h to hmm vm se koi request bahar nhi jaa paiga kuki pehle 
rule outbound hee check krega whee case agar outbound rule mai allow h or inbound mai block or hmm agar vm se request kr rhe to request bhi chla jaiga or 
response bhi aa jaiga kuki stateless h. NACL subnet pe lagta h or security group Network interface pe.

VPC peering - pehle check kr lena peer se pehle ki CIDR block dono k theek h phir peer krne k baad rout table bhi update krna padega taki jo new vpc 
bnaya uske CIDR wala traffic allow krde or jo idhar wala h usme bhi dusra wala update krde taki traffic jaa or aa ske dono VPC mai.

private Endpoint - hmm apne s3 ko data ko access krne k liye vm se (VPC Endpoint)private endpoint ka use kr skte h. isme ky hota ki request aws mai
privately jate h.

SSM session Manager - Isme ky hota h ky hmm vm ko SSM session manager pe add krte h to hmm security group mai port 22 bhi allow nhi krenge to bhi
hmm VM ko securely access kr skte h.

Roles
***********
jb hmm role create krte h to pehla option jo ata h wo hota h ki kis k liye role create krna or use baad ki ky ky access dena h.

***********************
AWS DEVOPS
***********************
Code Commit - here we will save our repo code it will use git in a backend
so when you create a repo in codecommit you need to to create a credentials for the user from the IAM -> user -> Security credentials -> Git credentials
for the codecommit

here we don't have an option to pull the code directly from the git here we need to first create the repo than clone in local and also clone the git
repo in local and that local repo can be pushed to created repo.

CodePipeline - Stages has multiple action groups

CodeBuild - buildspec.yaml this file we will have in s3 , bitbucket, or anywhere where we have our code and this will have intruction to build
our code.

ECS - Cluster - service - task - container

Cluster means containing all the services and tasks yha par hmm select kr skte h namespace phir infrasturucture mai AWS Fargate (serverless managed by azure),
AWS EC2 instances , External instances manual configuration we need to do. hmm container insights ko enable kr skte h details mai container ko janne
k liye par uske additional charges h 

Task definition - hmm json file se bhi define kr skte h or manual bhi phir uske baad infra fargate ya AWS EC2 task k liye phir network mode fargate k liye sirf 
awsvpc , AWS EC2 mai bridge hota h baki mai hmare icha h uske baad task size cpu or memory phir task role and task execution role inse hmm aws ki baki
service se connect kr skte h permission deke. phir uske baad container ki details image uri private registry h ya public private h to login details. Environment
variable define kr skte h health checks, storage mount kr skte h storage ko.

Service create krenge jha pe hmm vpc define krenge subnet define krnge. task definition select krenge select krenge kitne replica cheye or agar load balancer
cheye to wo bhi enable kr denge , security group select krenge update krenge rule security group mai puclic access dena ho to directly Public IP ko turned
on kr denge. Auto scaling enable kr skte h based on some rule.

EKS
**********
configure cluster - name , version of kubernetes, cluster service role- yha hmm role create krenge or assign krenge, cluster access - kaise access 
krenge api se config map se ya dono api or config map, secret encryption - isko enable kr skte h kubernetes secrets ko encrypt krne k liye KMS keys se.
Networking - VPC select , subnet select,security group select,IP family select,cluster end point mean kaise access hoga privately , public and private or sirf public
obervability - hmm Send Prometheus metrics to Amazon Managed Service for Prometheus enable kr skte h 
version select kr skte h - Amazon VPC CNI,CoreDNS ,kube-proxy,Amazon EKS Pod Identity Agent
Taint and Toleration mai add kr skta hu node group create krte hue
atlanta-datacenter-kkpwrvtcmh.dynamic-m.com
AKIA6BY4246BDEYBWJM2
MHCfGC4quv6UmouTdxWdpFIM1rbKmttzmc+XHvk6
aws eks --region us-east-1 update-kubeconfig --name Testing
aws eks list-clusters
kubectl patch deployment coredns -n kube-system --type json -p='[{"op": "remove", "path": "/spec/template/metadata/annotations/eks.amazonaws.com~1compute-type"}]'

***************************
Create EKS cluster
***************************
Configure cluster
Configure cluster - Cluster service role(AmazonEKSClusterPolicy)
Cluster access  - EKS API(The cluster will source authenticated IAM principals only from EKS access entry APIs.), EKS API and ConfigMap or ConfigMap
Secrets encryption - Turn on envelope encryption of Kubernetes secrets using KMS
Specify networking
VPC - VPC create krro usme private subnet or private subnet bnao (fargate use kroge to only private subnet select kr skte)
Private subnet - isko kaise create krte h - normal subnet create krre jo private subnet hote h usme hmm route table jo attach krte h usme hmm internet
gateway ka access nhi dete jo hmne VPC par attach kiya h. or agar hmme internet ka access dena h to hmm NAT gateway create krte h or uska access de 
dete h route table mai to agar hmm private subnet use kr rhe h to hmm route table mai NAT gateway ka access de denge EKS k node k liye taki wo connect
kr ske.
Public subnet mai ky hota h ki hmm direct route table mai internet gateway ka access de dete h or uss route table ko subnet se attach kr dete h.
Cluster endpoint access - Public(The cluster endpoint is accessible from outside of your VPC. Worker node traffic will leave your VPC to connect to the endpoint.)
Public and private(The cluster endpoint is accessible from outside of your VPC. Worker node traffic to the endpoint will stay within your VPC)
Private(The cluster endpoint is only accessible through your VPC. Worker node traffic to the endpoint will stay within your VPC.)
Configure observability
Metrics- Prometheus(Send Prometheus metrics to Amazon Managed Service for Prometheus)
Control plane logging - Send audit and diagnostic logs from the Amazon EKS control plane to CloudWatch Logs.(API server,Authenticator,Controller manager,Scheduler)

Ab jb cluster create ho jaye tab hmm rource mai jaakar Node group add krenge -
Node IAM role denge - AmazonEC2ContainerRegistryReadOnly,AmazonEKS_CNI_Policy,AmazonEKSWorkerNodePolicy
or tags mai kubernetes.io/cluster/my-cluster:owned jarur add krna.

Private cluster
********************
Private cluster create krne k liye vpc create krro phir uske baad phir subnet create krro private or public. private create krne k liye uske route 
table mai route internet gateway ko mt add krro jo internet gateway tumne VPC mai attach kiya h. public wale mai internet gateway ko attach krdo uske route
table mai. iske baad cluster create krro sirf private wale subnet select krro or create krdo. uske baad hmme master node ko access krne k liye access 
cheye hoga to usko fix krne k 2 tareeke h pehla to hmm NAT gateway create krre or private subnet k route table mai add krde dhyaan rhe NAT gateway 
create krenge hmm public subnet mai. dusra solution h ki hmm Endpoints create krre take master node ko access kr sake. jb hmm endpoint create krre 
hmme NAT gateway ki jarurat nhi padege private subnet mai. or iss tareke se hmm private cluster create kr painge.

Elastic Beanstalk
************************
Environment tier - Web server environment(Run a website, web application, or web API that serves HTTP requests), Worker environment(Run a worker application that processes long-running workloads on demand or performs tasks on a schedule.)
Provide default domain first name
Platform - type - Managed platform(Platforms published and maintained by Amazon Elastic Beanstalk), Custom platform(Platforms created and owned by you. This option is unavailable if you have no platforms.)
selct the type of platform - python,go,java,node etc and also select the version
Application code - code can be sample code directly upload into the application or we can connect s3 and point s3 to elastic beanstalk
select type of instant
select service role for elastic beanstalk this can be used to connect to other services in aws.
networking - select the VPC than instance setting whether public IP to be attached to EC2 instance also select the subnets 
select the setting for the database if you want to connect to database as well.
select volume for EC2 and if additional volume to be attached we can attach that as well select the timeperiod for cloudwatch monitoring, ec2 security group 
capicity max min instance instance type and other details.
steam logs to cloudwatch logs second rolling update type of update
environment property if any 

Parameter or variable
***********************
parameter store 
secret manager - these two we can use to keep our variables or secrets




CodeCommit
*************
Approval rule templates (You can create, manage, and delete approval rule templates. To associate or disassociate a template with one or more repositories in your AWS account, edit the template.)
code - where we can find all our files
Pull Request - if any request is raised for merging code into master
Branches - here we can list all our branches or create branches
Git tag - we can create a tag
Setting - 
 - notification - we can create a notification rule like on what thing notification will get trigger and that notification will trigger in which target
 like sns topic, aws chatbot(microsoft teams) etc
 - Trigger - - hmm trigger bhi create kr skte h usme hmm select kr skte h ki ky hoga agar kuch trigger hoga to.
 - AmazonCodeGuruReviewer - When you associate this repository with Amazon CodeGuru Reviewer, you will receive recommendations to help improve Java and Python code in all pull requests.
 
Jo agar kisi branch mai approval set krna h to hmme use krna approval rules template or wo branch ko add krna padega template mai.
agar hmme kisi particular branch pe push restrict krna h to hmm IAM mai particular user mai wo deny wali policy add kr denge or hmm group create krnege
or usme wo policy add kr denge policy add krne k baad user ko add kr denge.

CodeBuild 
*****************
version: 0.2

phases: 
    install:
        runtime-versions:
            nodejs: latest
        commands:
            - echo "installing something"
    pre_build:
        commands: 
            - echo "we are in the pre build phase"
    build:
        commands:
            - echo "we are in the build block"
            - echo "we will run some tests"
            - grep -Fq "Congratulations" index.html
    post_build:
        commands:
            - echo "we are in the post build phase"
			
one use case where we want to use both build and deploy -
phases:
  post_build:
    commands:
      - echo Entered the post_build phase...
      - zip -r site.zip ./*
      - echo Build completed on `date`
artifacts:
  files:
    - appspec.yml
    - site.zip
    - DeployScripts/*
	
Yha par hmm ky kr rhe h ki pehle hmne build kiye post_build mai hmne zip bnaya phir artifact mai hmne appspec.yml,zip plus deployscripts jo hmm 
appspec.yml mai use kiye h unsbko artifact mai send kr rhe h. take deployment step mai hmare pass sare cheeze rhe jo deploy krna h appspec.yml jha 
steps likhe h or scripts jo refer kr rhe h hmm appspec.yml mai.

Build project - yha par hmm define krne build krne ka processes
Build History - yha par hmare pass hoga already rained build
Report Group - yha par hmm group create krne jha par hmm display krra skenge Test ya code coverage report. or ye report hmm s3 se get kr skte h.
Report History - Yha par hmm dekh skenge report ki history
Account Metrics- Yha par hmm dekh skte h Builds ki metrics, Duration ki metrics, Succeed Build ki metrics and Failed build ki metrics.

Build Project 
******************
Build Project krte hue hmm source mention krna h konsa code build krna h uske baad Environment mention krna h ki AWS managed image use krnge ya apni khud
ki image use krenge phir select krne compute ya lamda uske baad operating system uske baad role select krnege agar koi VPC mai create krna h environment 
variable pass krna h ya file system uske baad hmm select krnge agar buildspec.yml file ka name kuch or h repo mai to uska naam mention krnge agar same
h to khali chord denge dusra bhi option h agar hmm command seeda pass krna cahte h to.
Batch configuration - You can run a group of builds as a single execution. Batch configuration is also available in advanced option when starting build
uske baad select kr skte h artifact pass krne ki location agar tum artifact create ho rha hmm usse s3 mai store kr skte h. cloud watch logs enable kr skte has

			
CodeDeploy
***************
Choose User Data: for installing required packages.
#!/bin/bash
sudo yum -y update
sudo yum -y install ruby
sudo yum -y install wget
cd /home/ec2-user
wget https://aws-codedeploy-ap-south-1.s3.ap-south-1.amazonaws.com/latest/install
sudo chmod +x ./install
sudo ./install auto
sudo yum install -y python-pip
sudo pip install awscli

Above commands we need to run if we want to deploy our code to EC2 or onPrem machine.
here we use appspec.yaml file
at source location of codedeploy hmare pass appspec.yml file hone cheye taki wo un steps ko read krke code deploy kr ske.
Deployments - yha pe list of rain pipeline hoga
Applications - yha par hmm application create krte h or deployment group ko register krte h  ab deployment group mai role select krenge phir type of deployment
select krenge ki kaise deployment hogi blue/green etc phir environment select krenge ki kha deploy krna h jaise ec2 onprem etc phir deployment setting ki kaise
deploy krna h saare 1k saath update ya 50 percentage at a time or 1 at a time phir last mai select krenge load balancer agar hmme load balancer use
krna h deployment ko manage krne k liye.
phir hmm isme trigger bhi rakh skte h Alarm rakh skte h rollback bhi agar krna cahte h to.


Here are the steps we have in buildspec.yaml file by default codeBuild look for buildspec.yaml file but if we have named differently than we can name
that in buildArtifact stage.

CodePipeline
****************
Yha par hmare pass saare cheeze hote h integrate krne ko codecommit codeBuild codedeploy sbko. codepipeline mai bhi hmm notification rule create kr skte h.

last mai settings hota h hmare pass developer tool mai gsse hmm connection ki help se connection create kr skte h third party tool k saath jaise
git github bitbucket gitlab etc.

ECS
*******************
ECS mai hmm sbse pehle cluster create krte h uske baad task definition create krte h task definition k baad hmm service create krte h. ab hmm container ko
directly bhi expose kr skte h public IP dekar or hmm container ko private subnet mai or ecr k saath endpoint create krke private mai bhi host kr skte has
sbse pehle hmm create krenge VPC usme hmm 2 public or 2 private subnet create krenge phir agar jo hmme public container create krna take hmm seeda
container ki public IP se usse access kr ske to hmm ky krenge ki hmm task defination create krnge phir service create krte time hmm VPC select krenge
usme phir public subnet select krenge or enable public IP wale ko enable kr denge service mai to ky hoga ki hmm seeda public IP jo container ko
assign hogi uske help se service ko access kr painge jo container mai run ho rhe h.
Ab agar hmm pura container sb cheez private mai run krne h to uske liye hmm enpoint create krne padenge VPC mai jo ki hmm ecr or ecrdkt service se 
connect krwaige directly. to hmm ky krnege end point create krenge or select krenge hmm private VPC.(com.amazonaws.us-east-1.ecr.api,com.amazonaws.us-east-1.ecr.dkr)
in dono k liye end point create kr dunga phir uske baad task definition define krunga gsme image name dunga jo mere ecr mai or uske baad phir service
create krunga gsme ki VPC select krunga phir private subnet select krunga or service create kr dunga ab jb service run hone lg jaige. uske baad phir 
manually application load balancer create krunga public subnet mai same vpc mai or target group mai IP select krunga or IP mai docker container ki
private IP de dunga or saath mai port de dunga mai. bss phir load balancer ki public dns se or port 80 se wo service access kr paunga.
agar mai private mai container run kr rha hu or mujhe monitoring bhi enable krne h or saath mai s3 ka access bhi dena h log store krne ko to mai un dono
k liye bhi endpoint create krunga.

Task definition mai -
hmm select krenge fargate use krna h ya ec2 ec2 mai saare configuration krne padege fargate mai poore configuration hue hoge usse aws manage krta h 
task role - take ye api call kr ske AWS mai container 
task execution role
container details select krro
port mapping krro
environment variable h to wo add krro
loggging enable krne h to wo krro 
health check bhi lage ske h 
container ki network setting ya container mai volume add ye sb kr skte h 

Service definition - 
Environment - compute configuration
Deployment type standalone task run krna h ya service ki help se run krna h 
task select krro
replica do
Deployment option do - rolling update ya blue green
Deployment failure mai ky krega rollback kr dega jo changes kiya ya ky wo select krro 
Networking select kro kha run krna h kis VPC mai subnet mai public IP wgera
service autoscaling wgera
Load balancer create krna h to wo bhi select krro.
or create krdo iss service ki help se task definition jo di thi uske help se task run hone lg jaiga

S3
***********
max size - 5TB (5000GB)
if uploading more than 5gb file use multipart
To enable website hosting - bucket - properties - Static website hosting(enable)
we can enable the versioning by going to property of storage account and ecit the versioning and enabled
first version will be null once you enable the version and upload same version of new file version you will be able to see with file.
Replication only works if versioning is enabled
for replication go to management - create replication rule

S3 se hmm notification send kr skte h lamda function,SNS topic,SQS queue mai. isme hmm sbse pehle sqs create krenge policy edit krenge sqs ki so that
s3 bucket notification send krr skte. jb policy update ho jaige uske baad seeda add kr dunga s3 ki configuration mai. bucket - property - create notification
To enable CORS we need to give the core setting there.
To enable logging - bucket - properties - server access login - enable
To share a presigned url meANS PRIVATE bucket data can be visible for someone for particular amount of time if we share presigned url. bucket->data->moreoption->presigned url
Access point - jaise ki agar hmme agar bucket k andar kisi folder ka access dena h to access point create krenge uske liye

CloudWatch 
********************
Logs - cloud watch mai logs enable krne pe aa jate h. hmm query kr skte h cloudwatch mai.
log group create kr skte h. uske baad usko materix mai daal k alarm set kr skte h.
Cloudwatch mai logs laane k liye ec2 instance se hmm agent install krenge phir uske help se hmm logs cloudwatch mai dekh skte h.
Alarm - on various option alarm will get trigger min,max or percentage. state of alarm ok,Insufficient_data,alarm(where all the things met and alarm will get trigger)
Alarm main targets - EC2,EC2 Autoscaling, SNS(from sns topic we can do whatever we want to do)
Composite alarm - states or multiple other alarms and we can use and or conditions.
hmm test kr skte h alarm ko aws ki set alarm service se. hmm wo value pass kr skte h gsse alarm trigger hoga.

AWS Cloud Trail
********************
cloud trail mai saare logs store hote h jo bhi aws mai hmm krte h uska agar hmme dekhna h kisne ky kiya to hmm cloud trail logs mai dekh skte h
sdk cli console iam users and roles k saare logs store hote h cloud trail mai.

AWS config
***************
it is used to monitor resources in aws like if we want to check whether our resources are compliant or not we can define in aws config and based on 
that we can send notifications with the help of sns topic. or we can do other automation

Code commit - 
privatelink
AmanSingh-at-965891254146
EventBridge
AWS WAF 
API gateway
Route53
certificate manager
s3
sqlcmd -S localhost -U sa -C



APIM for test environment

***********************************
EKS
***********************************
eksctl create nodegroup --config-file=eksctl-create-ng.yml
bigger the node larger the number of pods

we can also use vertical auto scaling in kubernetes but it is not recommended for production environment as it restarts the pods. 

Logs single place pe store krne k liye hmm - fluentbit use kr skte h wo daemon set run hota h cluster mai means in each worker node

Agar hmm kisi pod ya daemonset ko access dena cahte h to hmm ky krenge ki service account create krenge kubernetes mai or usme role attach kr denge jo
hmne aws mai create kiya h or uss service account ko attach kr denge hmm pod ya daemon set se.

promotheus
************
Monitor kubernetes cluster
Query time series data to generate graph
create alerts
Open source
it use promql

Grphana
********
Visualize metrics
works out of the box with prometheus
Create Alerts
Open Source

AWS Cloud watch = Graphana + Promotheus

Namespace -
Multiple virtual cluster boundary within one physical cluster
Provides scope for naming
Divide cluster resources to namespaces
useful for namespace

Sidecar container means container will be running in same pod
Daemon means pod will be running in node.

Amazon VPC CNI Plugin
Pod IP is same throughout the VPC in VPC CNI Plugin in Amazon
yha pe POD ko bhi IP address milega subnet se jo VPC mai h
tb yha ky hoga ki koi bhi pod kisi bhi pod se connect kr skta ab agar mujhe ye nhi cheye cluster mai to mai ky krunga ki networkPolicy define 
krunga cluster ki kon kha se access hona cheye. or networkPolicy define krne k liye hmm yml file use krte h gska type hota h NetworkPolicy
Networkpolicy hmm create krenge namespace mai or usme podselector de denge 

Cost Optimization in EKS
Right Sizing - dekhna ky right size ki nodes h ya nhi
Auto scaling - scale enable kr dena
Down Scaling - jaise ki weekends mai down kr dena taki cost jyada na aye
purchase - use krna spot instance,saving plan etc
Tools we can use to check the cost - kubecost,New Relic,CloudHealth by vmvare

AWS Direct Connect
*********************
A dedicated high bandwidth link for a private connection.

VPN
**********
Encrypted connection over internet

Cost Explorer
*****************
to check the cost overview currently or for future

Budget
**********
we can set budget

Load balancer 
*******************
Application Load balancer - for htt/https
Gateway Load balancer - Routes traffic to VPN
Network Load balancer - for TCP/UDP

Migration strategy
*********************
lift shift,re-platforming,re achitecting



Role vs clusterrole
********************
jb hmm role create krte h to wo kisi specific resource group mai create kr skte h whee jb hmm clusterrole create krte h to wo global hota h kisi bhi 
namespace mai use kr skte h or kisi specific namespace mai bind nhi rehta. clusterrole mai namespace nhi dete iska mtlb ye nhi ki wo default namespace mai
rehta h wo globally rehta h. baki role mai agar hmm namespace nhi denge to wo default namespace mai create ho jaiga.

Kube config file 
**********************
iss file mai Cluster name, Contexts iska mtlb username and cluster name , users means usersname ab agar config file mai multiple cluster or
multiple user h to wo execute krenga command base on current-context: parameter means gss bhi cluster ko current-context point kr rha hoga uss cluster
mai execute krega wo command.

To assign role to new user 
***************************
create role
create rolebinding for particular user
jb ye create ho jaye tb config map mai jao userarn ki details daalo

ECR - scanning 
EKS worker node scanning - we can use AWS EKS optimized AMI for worker node
Container runtime scanning means we can scan the container which is running with the help of AWS guardduty.
New user for database
*****************************
CREATE USER user_account IDENTIFIED BY password;
 
Azure Boards
**************
Process ko edit krne k liye hmm -
**********************************
Process mtlb ki scrum,agile,basic etc or agar hmme koi modified version cheye to hmm ky krenge ki organisation setting -> process -> create inherit process krenge 
jb new process create ho jaige phir hmm uss process mai jainge or agar hmme kisi bhi work item mai koi naya field add ya remove krna hoga to hmm wo
kr skte h even agar hmme koi new work item create krna h to wo bhi kr skte h agar phir hmm uss work item mai jaakar states bhi add kr skte h jaise 
ki new complete or koi bhi apni need k hisab se. hmm rules bhi create kr skte h agar krna ho to. so jo bhi modification krna h fields mai work Items
k liye wo yhe se hoga.

Follow for notifications - ye hmm enable krte h jb hmme kisi cheez k liye notification enable krna hota h.
Sbse pehle hmme agar process change krne h project ki like scrum, basic ya agile to hmm organisation setting mai jakr kr denge.
phir uske baad hmm teams create krte h Project settings -> Teams  mai jaakr or whee se user ko add ya invite bhi kr skte h
Ab hmm sprint create krne k liye project settings -> Project configuration -> Iteration (yha hmm release add kr skte h uske andar iteration add kr skte has
h jaise ki release 2 month mai hota h to project k andar release 1 add kiya uske andar 2 iteration add kr diye jo 2 week k hote h itration ya sprint.
Area mai hmm add kr skte h multiple area jaise socho ki hmare multiple teams h or hmm koi alg alg area pe kaam krta h to uske liye hmm area add krte h 
ye sb krne k badd hmm ate h project settings -> Team configuration mai phir select krte h General setting jaise ki Backlog item mai ky ky hoga, working days
uske baad hmm ate h iteration wale section mai whaa hmm select krte h jo iteration or release hmne create kiye. Area mai hmm area ko select krte h
Phir template mai hmm set krte h template particular EPIC Feature ya Task k liye

Ab jb ye saare configuration ho jaye tb ate h hmm boards pe -> work item -> yha hm create krte h EPIC 
Epic create krne k baad hmm ate h backlog pe or select krte h right side se EPIC to wo hmme saare EPIC show kr dega jo hmne create kiye honge
Uske baad hmm EPIC k andar Feature , feature k andar task create krte h
(Yha hmare pass setiing h column option gske use se hmm apne table mai additional column add ya remove kr skte based on apni need, agar hmme kisi ko 
details mail krne h to hmm directy task open krke extreme right mai three  dots mai click krke whaa se send email k option se kr skte h, whaa se hmm
task ka template bhi bna skte h or agar hmme same task khee or bnana ho to wo template hmm use kr skte h) 
Phir ata h hmare pass Queries yha se hmm different query create krke rakh skte h or baad mai un queries se direct result nikal skte h or agar hmme
Query ka result kisi graph mai dekhna h to hmm wo bhi dekh skte h chart ki help se or hmm uss chart ko directly dashboard mai bhi import kr skte h.

Dashboard - bhi hmm create kr skte h like Team Dashboard jo pure team k liye hoga or hmm kisi specific person k liye bhi create kr skte h dashboard.

Hmm Excel ko bhi connect kr skte h Azure Devops ko or task userstroy or jo bhi queries hmne likhe h whaa se saara data utha k hmm Excel sheet mai 
laa skte h Ecel ko Azure Devops se connect krke.
f209e44caedd7a8a77620b16a0f941752a77d1881ad372169d18d0fc550d27f23862a6bb18f8a7500b51f9fc2072ac40a5878e879fcedb09c41d06d4cad254bb

Database Administrator
**************************
Normalization - 

1NF
2NF
3NF
3NF is enough for production data
performance
identifier-{default}
recoveryenabled-yes

RDMS is the database whereas sql is command line which is used to intreact with database to get the data
Mysql,postgresql,oracledb,postgresql all these are database
https://www.youtube.com/watch?v=PFPt6PQNslE
Identity column means agar hmm likhte h IDENTITY(1,1) ye sql database khud se iss row ko 0 se start krega or +1 krta jaiga.
passport

Python
*************
string is immutable
str(num) to convert number to string
list
item = "a","b","c"
item.append("e")
item.insert(1,"b")
a in item result will be true
if condition:
   statement
elif condition:
   statement
else:
  statement

for loop
for item in exp:
    total = total + item
print(total)

for item in exp(1,4):
    total = total + item
	
print(total)item=["a","b","c"]
for i in item:
  if i=="b":
    print("we got our winner")
    break

item=["a","b","c"]
for i in item:
  if i=="b":
    print("we got our winner")
    break
	
Function
************
def total(sum):
  tot=0  
  for i in sum:
      tot = tot + int(i)
  return tot
  
Dictionary
***********
it will have key:value pair {"aman":"negi","ss":"ok"}
it will not be in any order

Tuple
*********
tuple is similar to list but it can store different type of value
tuple=("a",1,"ok")
it is immutable it means you won't be able to change the value in tuple

Modules
*************
we can import the central modules in python to utilize in our code or we can write our own module and import in our other files so 
that we don't have the write same code multiple time.

File
**********
f=open("c:\\data\\test.txt","w")
f.write("anything whatever you want to write")
f.close()

Python
*********
Decorator

_name_ from this method the exucution starts by default method in python like main in java and c++

30 july se theek
plans kisi ko nhi btana
wrong thought mai gud khana or pani peena or 11 baar apna naam lena h 

